{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_building.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWlLaF9rEpaz",
        "colab_type": "text"
      },
      "source": [
        "# **Introduction**\n",
        "The competition dataset contains text from works of fiction written by spooky authors of the public domain: **Edgar Allan Poe**, **HP Lovecraft** and **Mary Shelley**. The data was prepared by chunking larger texts into sentences using CoreNLP's MaxEnt sentence tokenizer, so you may notice the odd non-sentence here and there. The objective is to accurately identify the author of the sentences in the test set.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **Data Field**\n",
        "**id** - a unique identifier for each sentence\n",
        "\n",
        "**text** - some text written by one of the authors\n",
        "\n",
        "**author** - the author of the sentence (EAP: Edgar Allan Poe, HPL: HP Lovecraft; MWS: Mary Wollstonecraft Shelley)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJCc9Z83GZfn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "***This notebook is solely focused on model building using various machine learning algorithms. I would be focusing on getting the accuracy high .***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awd75v2-FeCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing required libraries\n",
        "\n",
        "import numpy as np\n",
        "from numpy import dstack\n",
        "import tensorflow as tf\n",
        "import operator\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import warnings\n",
        "import multiprocessing as mp\n",
        "import string\n",
        "import en_core_web_sm\n",
        "import spacy\n",
        "from random import randrange\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import Input,Embedding,Dense,LSTM,GRU,Bidirectional,Dropout,SimpleRNN,GlobalAvgPool1D,GlobalMaxPool1D\n",
        "from tensorflow.keras.layers import Conv1D,SpatialDropout1D,BatchNormalization,Lambda,Concatenate,concatenate,GlobalMaxPooling1D\n",
        "from tensorflow.keras.callbacks import  EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6gP4l4wtwPq",
        "colab_type": "code",
        "outputId": "187b8fcc-ebcd-43b9-b478-70d74b661da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "warnings.filterwarnings('ignore')\n",
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lywq_gcurrDS",
        "colab_type": "code",
        "outputId": "45303e3b-3c57-45c1-d1f6-587ee2e156f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id26305</td>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id17569</td>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id11008</td>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27763</td>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id12958</td>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                               text author\n",
              "0  id26305  This process, however, afforded me no means of...    EAP\n",
              "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
              "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
              "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
              "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nnj42yArwv5",
        "colab_type": "code",
        "outputId": "0cc06a5c-837f-4d49-ca6e-b8536fdbe281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19579 entries, 0 to 19578\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      19579 non-null  object\n",
            " 1   text    19579 non-null  object\n",
            " 2   author  19579 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 459.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG8z2vGFtRO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing id column\n",
        "df.drop('id',axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af0fWTupzmT8",
        "colab_type": "text"
      },
      "source": [
        "## Removing outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B06_oRRx0BGC",
        "colab_type": "code",
        "outputId": "51212e59-06eb-491c-ef54-dc8faedc761e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "df = df[df['text'].str.split().map(lambda x:len(x))<100]\n",
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 26558 entries, 0 to 26680\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    26558 non-null  object\n",
            " 1   author  26558 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 622.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTpSQm3PteWj",
        "colab_type": "text"
      },
      "source": [
        "# **Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVUKiUI9c_iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextPreprocessing(BaseEstimator,TransformerMixin):\n",
        "    def __init__(self,\n",
        "                 n_jobs=1):    \n",
        "      \n",
        "     self.n_jobs = n_jobs\n",
        "    \"\"\"\n",
        "        Text preprocessing transformer includes steps:\n",
        "            1. Text normalization\n",
        "            2. Punctuation removal\n",
        "            3. Stop words removal\n",
        "            4. Lemmatization\n",
        "        \n",
        "        n_jobs - parallel jobs to run\n",
        "    \"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, *_):\n",
        "        X_copy = X.copy()\n",
        "        partitions = 2\n",
        "        cores = mp.cpu_count()\n",
        "        if self.n_jobs <= -1:\n",
        "          partitions = cores\n",
        "        elif self.n_jobs <= 0:\n",
        "          return X_copy.apply(self._preprocess_text)\n",
        "        else:\n",
        "          partitions = min(self.n_jobs, cores)\n",
        "        cores = mp.cpu_count()\n",
        "        data_split = np.array_split(X_copy, partitions)\n",
        "        pool = mp.Pool(cores)\n",
        "        data = pd.concat(pool.map(self._preprocess_part, data_split))\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "        return data\n",
        "\n",
        "    def _preprocess_part(self, part):\n",
        "        return part.apply(self._preprocess_text)\n",
        "\n",
        "    def _preprocess_text(self, text):\n",
        "        normalized_text = self._normalize(text)\n",
        "        doc = nlp(normalized_text)\n",
        "        removed_punct = self._remove_punct(doc)\n",
        "        removed_stop_words = self._remove_stop_words(removed_punct)\n",
        "        return self._lemmatize(removed_stop_words)\n",
        "\n",
        "    def _normalize(self, text):\n",
        "        # some issues in normalise package\n",
        "        try:\n",
        "            return ' '.join(normalise(text, verbose=False))\n",
        "        except:\n",
        "            return text\n",
        "    def _remove_punct(self, doc):\n",
        "        return [t for t in doc if t.text not in string.punctuation]\n",
        "\n",
        "    def _remove_stop_words(self, doc):\n",
        "        return [t for t in doc if not t.is_stop]\n",
        "\n",
        "    def _lemmatize(self, doc):\n",
        "        return ' '.join([t.lemma_ for t in doc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxDyIS4R5TwT",
        "colab_type": "code",
        "outputId": "39139a40-b95d-454e-f138-e28ffefa5903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "#Converting the categorical column to variable\n",
        "\n",
        "df['author'] = df['author'].map({'EAP':0,'HPL':1,'MWS':2})\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  author\n",
              "0  This process, however, afforded me no means of...       0\n",
              "1  It never once occurred to me that the fumbling...       1\n",
              "2  In his left hand was a gold snuff box, from wh...       0\n",
              "3  How lovely is spring As we looked from Windsor...       2\n",
              "4  Finding nothing else, not even gold, the Super...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5nVljDE5wqQ",
        "colab_type": "text"
      },
      "source": [
        "## Using countvectorizer to convert the sentence into column of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh1CVRhN2tKx",
        "colab_type": "code",
        "outputId": "4fb71c1a-5306-4dce-e8b4-db29a2e1802f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "cv = CountVectorizer()\n",
        "cv_df = cv.fit_transform(df['text'])\n",
        "\n",
        "tfidf = TfidfTransformer()\n",
        "tfidf.fit(cv_df)\n",
        "tfidf_trans = tfidf.transform(cv_df)\n",
        "\n",
        "print('Shape of Sparse Matrix: ', cv_df.shape)\n",
        "print('Amount of Non-Zero occurences: ', cv_df.nnz)\n",
        "print('Shape of Tfidf Transformed matrix',tfidf_trans.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Sparse Matrix:  (19579, 25068)\n",
            "Amount of Non-Zero occurences:  429602\n",
            "Shape of Tfidf Transformed matrix (19579, 25068)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHaNKxhq6Jd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the model into train and text split\n",
        "X_train,X_test,y_train,y_test = train_test_split(df['text'],df['author'],test_size = 0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idd8oR_NsMsa",
        "colab_type": "text"
      },
      "source": [
        "# **Baseline Model**\n",
        "\n",
        "\n",
        "\n",
        "## **1) Random prediction**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsm3HVJlr0b0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_pred(X_test):\n",
        "\n",
        "  unique = [1,2,3]\n",
        "  predicted = list()\n",
        "  for i in range(len(X_test)):\n",
        "    index = randrange(len(unique))\n",
        "    predicted.append(unique[index])\n",
        "  return predicted\n",
        "\n",
        "y_pred = random_pred(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsDsLAxGwPwR",
        "colab_type": "code",
        "outputId": "1e282fc1-17c6-4318-bb7f-42b3413aba4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[790 777 749]\n",
            " [557 574 534]\n",
            " [614 630 622]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.40      0.34      0.37      2316\n",
            "           2       0.29      0.34      0.31      1665\n",
            "           3       0.33      0.33      0.33      1866\n",
            "\n",
            "    accuracy                           0.34      5847\n",
            "   macro avg       0.34      0.34      0.34      5847\n",
            "weighted avg       0.35      0.34      0.34      5847\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhkwyQPbMNmv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTCa-Gd09ua0",
        "colab_type": "text"
      },
      "source": [
        "### **The baseline model got an accuracy of 33% , which is reasonable**\n",
        "### **because we are randomly picking the classes,therefore 1/3 chances of getting it right** \n",
        "\n",
        "# **2) Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlhBTRzvcnMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Logistic = LogisticRegression()\n",
        "pipeline = Pipeline([('text',TextPreprocessing()),\n",
        "                     ('count' , CountVectorizer()),\n",
        "                     ('tfidf' , TfidfTransformer()),\n",
        "                     ('model' , LogisticRegression())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9TbitHgoG8b",
        "colab_type": "code",
        "outputId": "6e50494e-a106-4d04-d32a-aa9643a32a39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "pipeline.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('text', TextPreprocessing(n_jobs=1)),\n",
              "                ('count',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w...\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('model',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_y5Lgcpot2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = pipeline.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtxMbz6r1QlL",
        "colab_type": "code",
        "outputId": "a21b0bba-9852-421f-853f-87835e399320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "print(confusion_matrix(y_test,pred))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1986  162  168]\n",
            " [ 312 1253  100]\n",
            " [ 327  114 1425]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.76      0.86      0.80      2316\n",
            "           2       0.82      0.75      0.78      1665\n",
            "           3       0.84      0.76      0.80      1866\n",
            "\n",
            "    accuracy                           0.80      5847\n",
            "   macro avg       0.81      0.79      0.80      5847\n",
            "weighted avg       0.80      0.80      0.80      5847\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zKlJDcuPaic",
        "colab_type": "text"
      },
      "source": [
        "### **A simple Logistic Regression model produced about 80% accuracy even without hypertuning the parameters. It would be interesting to see whether it is possible to outperform this model.**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **3) Support Vector Machines**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF1y9jFpJC7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = Pipeline([('text',TextPreprocessing()),\n",
        "                     ('count',CountVectorizer()),\n",
        "                     ('tfidf',TfidfTransformer()),\n",
        "                     ('model',SVC())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1t_6WmHTkZ7",
        "colab_type": "code",
        "outputId": "ae99798f-401d-430f-8fff-4d02a6612e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "pipeline.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('text', TextPreprocessing(n_jobs=1)),\n",
              "                ('count',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w...\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('model',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                     probability=False, random_state=None, shrinking=True,\n",
              "                     tol=0.001, verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlWDzHXZfuxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = pipeline.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXCq0m9lgyU2",
        "colab_type": "code",
        "outputId": "3188f1a2-fd79-4855-ec40-cd1c94c836f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "print(confusion_matrix(y_test,pred))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2011  133  172]\n",
            " [ 333 1235   97]\n",
            " [ 393  107 1366]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.73      0.87      0.80      2316\n",
            "           2       0.84      0.74      0.79      1665\n",
            "           3       0.84      0.73      0.78      1866\n",
            "\n",
            "    accuracy                           0.79      5847\n",
            "   macro avg       0.80      0.78      0.79      5847\n",
            "weighted avg       0.80      0.79      0.79      5847\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZoChOuehJwY",
        "colab_type": "text"
      },
      "source": [
        "## **Yikes! The model accuracy got reduced , all good though! Onto the next model!!**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **4) Naive Bayes classifier**\n",
        "\n",
        "A Naive Bayes text classifier is based on the Bayes's Theorem, which helps us compute the conditional probabilities of occurrence of two events based on the probabilities of occurrence of each individual event, encoding those probabilities is extremely useful.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-7aq_CNhGAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = Pipeline([('text',TextPreprocessing()),\n",
        "                     ('count',CountVectorizer()),\n",
        "                     ('Tfidf',TfidfTransformer()),\n",
        "                     ('model',MultinomialNB())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdmN0HG0iAXj",
        "colab_type": "code",
        "outputId": "ea6c3a65-ca2c-4181-9eb5-2323d59c75b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "pipeline.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('text', TextPreprocessing(n_jobs=1)),\n",
              "                ('count',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, vocabulary=None)),\n",
              "                ('Tfidf',\n",
              "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
              "                                  sublinear_tf=False, use_idf=True)),\n",
              "                ('model',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irdp8xB2iDey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = pipeline.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEqBl1aBi6lR",
        "colab_type": "code",
        "outputId": "d3b5c929-90a0-4efb-9161-d256e3156e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "print(confusion_matrix(y_test,pred))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2031   84  201]\n",
            " [ 362 1194  109]\n",
            " [ 312   53 1501]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.75      0.88      0.81      2316\n",
            "           2       0.90      0.72      0.80      1665\n",
            "           3       0.83      0.80      0.82      1866\n",
            "\n",
            "    accuracy                           0.81      5847\n",
            "   macro avg       0.83      0.80      0.81      5847\n",
            "weighted avg       0.82      0.81      0.81      5847\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTp6oN4ijayQ",
        "colab_type": "text"
      },
      "source": [
        "## **The accuracy increased, this shows that naive bayes is really good for text classification tasks. The next model will be hypertuned using randomizedsearchcv**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **5) RandomForest Classifier with GridSearch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZC8FNtAjNf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline_forest = Pipeline([('text',TextPreprocessing()),\n",
        "                     ('count',CountVectorizer()),\n",
        "                     ('tfidf',TfidfTransformer()),\n",
        "                     ('model_forest', RandomForestClassifier(n_estimators=1500))])\n",
        "\n",
        "params = {'model_forest__n_estimators':[75,100,350,500,1000,5000],'model_forest__min_samples_split': [2, 5, 10]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5t9T6cZyJJj",
        "colab_type": "code",
        "outputId": "8c42ebee-1e95-40a0-f574-38ece15857fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid_forest = RandomizedSearchCV(pipeline_forest,param_distributions=params,refit=True,verbose=3,n_iter=2)\n",
        "grid_forest.fit(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
            "[CV] model_forest__n_estimators=500, model_forest__min_samples_split=5 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  model_forest__n_estimators=500, model_forest__min_samples_split=5, score=0.702, total= 3.6min\n",
            "[CV] model_forest__n_estimators=500, model_forest__min_samples_split=5 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.6min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  model_forest__n_estimators=500, model_forest__min_samples_split=5, score=0.693, total= 3.6min\n",
            "[CV] model_forest__n_estimators=500, model_forest__min_samples_split=5 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.2min remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  model_forest__n_estimators=500, model_forest__min_samples_split=5, score=0.686, total= 3.6min\n",
            "[CV] model_forest__n_estimators=500, model_forest__min_samples_split=5 \n",
            "[CV]  model_forest__n_estimators=500, model_forest__min_samples_split=5, score=0.694, total= 3.6min\n",
            "[CV] model_forest__n_estimators=500, model_forest__min_samples_split=5 \n",
            "[CV]  model_forest__n_estimators=500, model_forest__min_samples_split=5, score=0.707, total= 3.7min\n",
            "[CV] model_forest__n_estimators=350, model_forest__min_samples_split=2 \n",
            "[CV]  model_forest__n_estimators=350, model_forest__min_samples_split=2, score=0.699, total= 3.7min\n",
            "[CV] model_forest__n_estimators=350, model_forest__min_samples_split=2 \n",
            "[CV]  model_forest__n_estimators=350, model_forest__min_samples_split=2, score=0.691, total= 3.7min\n",
            "[CV] model_forest__n_estimators=350, model_forest__min_samples_split=2 \n",
            "[CV]  model_forest__n_estimators=350, model_forest__min_samples_split=2, score=0.681, total= 3.7min\n",
            "[CV] model_forest__n_estimators=350, model_forest__min_samples_split=2 \n",
            "[CV]  model_forest__n_estimators=350, model_forest__min_samples_split=2, score=0.692, total= 3.7min\n",
            "[CV] model_forest__n_estimators=350, model_forest__min_samples_split=2 \n",
            "[CV]  model_forest__n_estimators=350, model_forest__min_samples_split=2, score=0.695, total= 3.7min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 36.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=None, error_score=nan,\n",
              "                   estimator=Pipeline(memory=None,\n",
              "                                      steps=[('text',\n",
              "                                              TextPreprocessing(n_jobs=1)),\n",
              "                                             ('count',\n",
              "                                              CountVectorizer(analyzer='word',\n",
              "                                                              binary=False,\n",
              "                                                              decode_error='strict',\n",
              "                                                              dtype=<class 'numpy.int64'>,\n",
              "                                                              encoding='utf-8',\n",
              "                                                              input='content',\n",
              "                                                              lowercase=True,\n",
              "                                                              max_df=1.0,\n",
              "                                                              max_features=None,\n",
              "                                                              min_df=1,\n",
              "                                                              ngram_range=(1,\n",
              "                                                                           1),\n",
              "                                                              preprocessor=None,\n",
              "                                                              stop_wo...\n",
              "                                                                     n_jobs=None,\n",
              "                                                                     oob_score=False,\n",
              "                                                                     random_state=None,\n",
              "                                                                     verbose=0,\n",
              "                                                                     warm_start=False))],\n",
              "                                      verbose=False),\n",
              "                   iid='deprecated', n_iter=2, n_jobs=None,\n",
              "                   param_distributions={'model_forest__min_samples_split': [2,\n",
              "                                                                            5,\n",
              "                                                                            10],\n",
              "                                        'model_forest__n_estimators': [75, 100,\n",
              "                                                                       350, 500,\n",
              "                                                                       1000,\n",
              "                                                                       5000]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring=None, verbose=3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVrpBOHUyUUr",
        "colab_type": "code",
        "outputId": "ab02ff5c-669b-491c-d521-88246ce425a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "grid_forest.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model_forest__min_samples_split': 5, 'model_forest__n_estimators': 500}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bikIfqmkBNH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_forest = grid_forest.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZsyBmTICEMQ",
        "colab_type": "code",
        "outputId": "8679d9f1-e430-43d3-d992-d26de7a06fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred_forest))\n",
        "print('\\n')\n",
        "print(classification_report(y_test,y_pred_forest))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1698  260  358]\n",
            " [ 361 1111  193]\n",
            " [ 379  152 1335]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.70      0.73      0.71      2316\n",
            "           2       0.73      0.67      0.70      1665\n",
            "           3       0.71      0.72      0.71      1866\n",
            "\n",
            "    accuracy                           0.71      5847\n",
            "   macro avg       0.71      0.71      0.71      5847\n",
            "weighted avg       0.71      0.71      0.71      5847\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQiKY0PGFSHD",
        "colab_type": "text"
      },
      "source": [
        "## **Oops! The accuracy greatly decreased! Even with hyperparameter tuning.MultinomialNB() is still at the lead with 81% accuracy.Onto Neural Networks!!**\n",
        "\n",
        "\n",
        "---\n",
        "# **6) Neural Networks**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLiMqHrqSY5e",
        "colab_type": "code",
        "outputId": "92a28bc5-e9c5-4ca5-ea5b-a5fb22bedb38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "df_neural = df\n",
        "df_neural.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  author\n",
              "0  This process, however, afforded me no means of...       0\n",
              "1  It never once occurred to me that the fumbling...       1\n",
              "2  In his left hand was a gold snuff box, from wh...       0\n",
              "3  How lovely is spring As we looked from Windsor...       2\n",
              "4  Finding nothing else, not even gold, the Super...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4567q8afLHu",
        "colab_type": "code",
        "outputId": "d8498690-0eac-4231-88aa-a140a0c610bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "stop = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def convert_nltk_to_wordnet(text):\n",
        "#To check if the given word is noun,or a verb or an adjective\n",
        "  if text.startswith('J'):\n",
        "    return wordnet.ADJ\n",
        "  \n",
        "  elif text.startswith('N'):\n",
        "    return wordnet.NOUN\n",
        "\n",
        "  elif text.startswith('V'):\n",
        "    return wordnet.VERB\n",
        "  \n",
        "  elif text.startswith('R'):\n",
        "    return wordnet.ADV\n",
        "  \n",
        "  else:\n",
        "    return None \n",
        " \n",
        "def lemmatizes(sentence):\n",
        "  tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
        "  wordnet_tagged = map(lambda x : (x[0] , convert_nltk_to_wordnet(x[1])) , tagged)\n",
        "  lemmatized_sentence = []\n",
        "  for word , tag in wordnet_tagged:\n",
        "    if tag is None:\n",
        "      lemmatized_sentence.append(word)\n",
        "    else:\n",
        "      lemmatized_sentence.append(lemmatizer.lemmatize(word,tag))\n",
        "  return ' '.join(lemmatized_sentence)\n",
        "\n",
        "def clean(text):\n",
        "\n",
        "  text = re.sub('/.',' ',text)\n",
        "  text = text.lower()\n",
        "  text = re.sub(\"aren't\", \"are not\",text)\n",
        "  text = re.sub(\"can't\",\"cannot\",text)\n",
        "  text = re.sub(\"don't\",\"do not\",text)\n",
        "  text = re.sub(\"couldn't\",\"could not\",text)\n",
        "  text = re.sub(\"doesn't\",\"does not\",text)\n",
        "  text = re.sub(\"hadn't\",\"had not\",text)\n",
        "  text = re.sub(\"wouldn't\",\"would not\",text)\n",
        "  text = re.sub(\"he'll\",\"he will\",text)\n",
        "  text = re.sub(\"what've\",\"what have\",text)\n",
        "  text = re.sub(\"who'd\",\"who would\",text)\n",
        "  text = re.sub(\"who'll\",\"who will\",text)\n",
        "  text = re.sub(\"I'll\",\"I will\",text)\n",
        "  text = re.sub(\"you'd\",\"you would\",text)\n",
        "  text = re.sub(\"you'll\",\"you will\",text)\n",
        "  text = re.sub(\"you're\",\"you are\",text)\n",
        "  text = re.sub(\"you've\",\"you have\",text)\n",
        "  text = re.sub(\"wasn't\",\"was not\",text)\n",
        "  text = re.sub(\"that's\",\"that is\",text)\n",
        "  text = re.sub(\"they've\",\"they have\",text)\n",
        "  text = re.sub(\"they're\",\"they are\",text)\n",
        "  text = re.sub(\"what's\",\"what is\",text)\n",
        "  text = re.sub(\"what're\",\"what are\",text)\n",
        "  text = re.sub(\"what'll\",\"what will\",text)\n",
        "  text = re.sub(\"that's\",\"that is\",text)\n",
        "  text = re.sub(\"there's\",\"there is\",text)\n",
        "  text = re.sub(\"it's\",\"it is\",text)\n",
        "  text = re.sub(\"it'll\",\"it will\",text)\n",
        "  text = re.sub(\"could've\",\"could have\",text)\n",
        "  text = re.sub(\"it'll\",\"it will\",text)\n",
        "  text = re.sub(\"shouldn't\",\"should not\",text)\n",
        "  text = re.sub(\"should've\",\"should have\",text)\n",
        "  text = re.sub(\"shan't\",\"shall not\",text)\n",
        "  text = re.sub(\"won't\",\"will not\",text)\n",
        "  text = re.sub(\"we'd\",\"we would\",text)\n",
        "  text = re.sub(\"weren't\",\"were not\",text)\n",
        "  text = re.sub('[^A-Za-z/.\\s]','',text)\n",
        "  text = text.lower().split()\n",
        "  text = [word for word in text if word not in stop]\n",
        "  text = ' '.join(text)\n",
        "  final_text = lemmatizes(text)\n",
        "  return final_text\n",
        "\n",
        "df_neural['text'] = df_neural['text'].apply(lambda x : clean(x))\n",
        "y = to_categorical(df['author'])\n",
        "df_neural.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>process however afford mean ascertain dimensio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>never occur fumble might mere mistake .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>left hand gold snuff box caper hill cut manner...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lovely spring look windsor terrace sixteen fer...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>find nothing else even gold superintendent aba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  author\n",
              "0  process however afford mean ascertain dimensio...       0\n",
              "1            never occur fumble might mere mistake .       1\n",
              "2  left hand gold snuff box caper hill cut manner...       0\n",
              "3  lovely spring look windsor terrace sixteen fer...       2\n",
              "4  find nothing else even gold superintendent aba...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gpOUBRHGuwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embedding(name,word_index,vocab_len,dim):\n",
        "  embedding_index = {}\n",
        "  f = open(name,encoding='utf-8')\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coeffs = np.asarray(values[1:],dtype='float32')\n",
        "    embedding_index[word] = coeffs\n",
        "  f.close()\n",
        "  embedding_matrix = np.zeros((vocab_len+1,dim))\n",
        "  for word,index in word_index.items():\n",
        "    if index > vocab_len:\n",
        "      break\n",
        "    else:\n",
        "      embedding_vector = embedding_index.get(word)\n",
        "      if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector\n",
        "  return embedding_matrix,embedding_index\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjBM_1fCdX0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = np.asarray(df_neural['text'])\n",
        "tokenizer = Tokenizer(num_words=21000)\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "sequences = tokenizer.texts_to_sequences(corpus)\n",
        "data = pad_sequences(sequences=sequences,padding='pre')\n",
        "vocab_len = len(tokenizer.word_index)+1\n",
        "max_len = len(data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFJ7Es-KWHCW",
        "colab_type": "code",
        "outputId": "43ceb8fc-3aad-48c3-8b70-d0bf9c3d291f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "# Importing pre-trained glove embeddings\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-08 05:18:54--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-05-08 05:18:54--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-05-08 05:18:55--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: glove.6B.zip\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.01MB/s    in 6m 29s  \n",
            "\n",
            "2020-05-08 05:25:24 (2.11 MB/s) - glove.6B.zip saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4xRUnW3akmc",
        "colab_type": "code",
        "outputId": "d740cd67-5b3d-41d5-a8d9-7a31103102ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!unzip glove*.zip\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG7PYAkmamv2",
        "colab_type": "code",
        "outputId": "b2ce93c7-072e-4e8d-d366-8f48919c4284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t   glove.6B.200d.txt  glove.6B.50d.txt\tsample_data\n",
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\ttrain.csv\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFtGfV-dMwM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "embedding_matrix1,embedding_index1 = get_embedding('glove.6B.300d.txt',word_index,vocab_len,300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XBplzunc4b1",
        "colab_type": "code",
        "outputId": "14b8eca6-e4ae-49f1-d922-94a1aff7d122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "#Importing pretrained fasttest embeddings\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-08 05:26:39--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 2606:4700:10::6816:4a8e, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: wiki-news-300d-1M.vec.zip\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  11.0MB/s    in 60s     \n",
            "\n",
            "2020-05-08 05:27:40 (10.9 MB/s) - wiki-news-300d-1M.vec.zip saved [681808098/681808098]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfe4I_DFNRiU",
        "colab_type": "code",
        "outputId": "227a16d4-8f04-49f9-fc15-45aebce169bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!unzip wiki-news-300d-1M.vec*.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVUN9KJgNfAs",
        "colab_type": "code",
        "outputId": "b284943b-9e0d-4120-b7bb-740f4c28e896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!ls\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive\t\t   glove.6B.50d.txt  wiki-news-300d-1M.vec\n",
            "glove.6B.100d.txt  glove.6B.zip      wiki-news-300d-1M.vec.zip\n",
            "glove.6B.200d.txt  sample_data\n",
            "glove.6B.300d.txt  train.csv\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n05_MQ_fNih0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix2,embedding_index2 = get_embedding('wiki-news-300d-1M.vec',word_index,vocab_len,300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BTSRHNlxrxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking if we have word embeddings for the words in our vocab\n",
        "def check_coverage(vocab, embeddings_index):\n",
        "\n",
        "  known_words = {}\n",
        "  unknown_words = {}\n",
        "  nb_known_words = 0\n",
        "  nb_unknown_words = 0\n",
        "  for word in vocab.keys():\n",
        "    try:\n",
        "        known_words[word] = embeddings_index[word]\n",
        "        nb_known_words += vocab[word]\n",
        "    except:\n",
        "        unknown_words[word] = vocab[word]\n",
        "        nb_unknown_words += vocab[word]\n",
        "        pass\n",
        "  print('Found embeddings for {:.3%} of vocab'.format(len(known_words) / len(vocab)))\n",
        "  print('Found embeddings for  {:.3%} of all text'.format(nb_known_words / (nb_known_words + nb_unknown_words)))\n",
        "  unknown_words = sorted(unknown_words.items(), key=operator.itemgetter(1))[::-1]\n",
        "\n",
        "  return unknown_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYQMp6SIzzzJ",
        "colab_type": "code",
        "outputId": "b62c4659-fa12-4ef5-ca9b-46d106d1c603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "print('Glove embeddings:\\n')\n",
        "Glove_embedding = check_coverage(word_index,embedding_index1)\n",
        "print('\\n')\n",
        "print('Fasttext embeddings:\\n')\n",
        "Fasttext_embedding = check_coverage(word_index,embedding_index2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Glove embeddings:\n",
            "\n",
            "Found embeddings for 87.348% of vocab\n",
            "Found embeddings for  82.289% of all text\n",
            "\n",
            "\n",
            "Fasttext embeddings:\n",
            "\n",
            "Found embeddings for 87.610% of vocab\n",
            "Found embeddings for  82.676% of all text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izsoj6xQ0tGz",
        "colab_type": "code",
        "outputId": "76fecb04-3188-4dbd-89dc-e2536569b680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "#Let's see some of the unknown words of the text\n",
        "Glove_embedding[:30]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('brusquerie', 20245),\n",
              " ('tremulousness', 20238),\n",
              " ('aegidus', 20232),\n",
              " ('valentinianus', 20231),\n",
              " ('btenoir', 20227),\n",
              " ('junianus', 20226),\n",
              " ('littlewit', 20224),\n",
              " ('schweinkopf', 20219),\n",
              " ('apothegm', 20216),\n",
              " ('flatzplatz', 20215),\n",
              " ('literatim', 20211),\n",
              " ('odigies', 20209),\n",
              " ('despera', 20208),\n",
              " ('chinless', 20207),\n",
              " ('herbless', 20202),\n",
              " ('trink', 20201),\n",
              " ('deathful', 20199),\n",
              " ('contemns', 20181),\n",
              " ('servox', 20171),\n",
              " ('unpossessed', 20170),\n",
              " ('signalize', 20153),\n",
              " ('carvins', 20149),\n",
              " ('otaheit', 20146),\n",
              " ('miltonic', 20136),\n",
              " ('rayless', 20135),\n",
              " ('siroc', 20129),\n",
              " ('lascia', 20125),\n",
              " ('raggiar', 20124),\n",
              " ('lombra', 20121),\n",
              " ('othair', 20115)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQsnrrcg0-Ea",
        "colab_type": "text"
      },
      "source": [
        "### As we can see , we found the embeddings of 85% of the words which is quite good."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdoxK4ZpODcM",
        "colab_type": "code",
        "outputId": "7f494114-8887-4c6b-e301-c900b9ed5029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embedding_matrix_weights = np.mean((embedding_matrix1,embedding_matrix2),axis=0)\n",
        "np.shape(embedding_matrix_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20253, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0hyFPktBzV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# It's important to split the data into training , test and validation set\n",
        "X_train,X_test,y_train,y_test=train_test_split(data,y,test_size=0.2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRZ6GnSfgcUk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **7) Deep Neural Networks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOIU24unJOsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deep_1st():\n",
        "  model_deep = Sequential()\n",
        "  model_deep.add(Embedding(vocab_len+1,300,weights=[embedding_matrix_weights],trainable=True,input_length=max_len))\n",
        "  model_deep.add(SpatialDropout1D(0.2))\n",
        "  model_deep.add(Bidirectional(LSTM(128,input_shape=(64,1),return_sequences = True)))\n",
        "  #model_rnn.add(Lambda(lambda x: tf.expand_dims(model_rnn.output, axis=-1)))\n",
        "  model_deep.add(Bidirectional(LSTM(64,return_sequences=True)))\n",
        "  model_deep.add(GlobalMaxPool1D())\n",
        "  model_deep.add(Dense(128,activation='relu'))\n",
        "  model_deep.add(Dropout(0.5))\n",
        "  model_deep.add(BatchNormalization())\n",
        "  model_deep.add(Dense(3,activation='softmax'))\n",
        "\n",
        "  callbacks = EarlyStopping(monitor='val_loss',patience=5)\n",
        "\n",
        "  model_deep.compile(optimizer = 'adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model_deep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzYfWvVPyQCN",
        "colab_type": "code",
        "outputId": "e2b15d2a-9a4a-45e9-ba39-85cebf5459d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold = StratifiedKFold(n_splits=5,shuffle=True)\n",
        "i=1\n",
        "score=[]\n",
        "for train_index , test_index in kfold.split(X_train,y_train.argmax(1)):\n",
        "    print('{} of KFold {}'.format(i,kfold.n_splits))\n",
        "    X_train1,X_test1 = X_train[train_index],X_train[test_index]\n",
        "    y_train1,y_test1 = y_train[train_index],y_train[test_index]\n",
        "    model_1 = deep_neural()\n",
        "    history = model_1.fit(X_train1,y_train1,batch_size=512,epochs=8,validation_split=0.2)\n",
        "    print('\\n')\n",
        "    acc = model_1.evaluate(X_test1,y_test1)\n",
        "    print('Accuracy :  ',acc[1])\n",
        "    score.append(acc[1])\n",
        "    print('\\n')\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 of KFold 5\n",
            "Epoch 1/8\n",
            "27/27 [==============================] - 4s 158ms/step - loss: 0.9691 - accuracy: 0.5510 - val_loss: 1.0172 - val_accuracy: 0.5374\n",
            "Epoch 2/8\n",
            "27/27 [==============================] - 3s 122ms/step - loss: 0.6482 - accuracy: 0.7288 - val_loss: 0.9078 - val_accuracy: 0.6729\n",
            "Epoch 3/8\n",
            "27/27 [==============================] - 3s 120ms/step - loss: 0.4357 - accuracy: 0.8309 - val_loss: 0.7894 - val_accuracy: 0.7203\n",
            "Epoch 4/8\n",
            "27/27 [==============================] - 3s 120ms/step - loss: 0.2973 - accuracy: 0.8909 - val_loss: 0.6426 - val_accuracy: 0.7947\n",
            "Epoch 5/8\n",
            "27/27 [==============================] - 3s 118ms/step - loss: 0.2153 - accuracy: 0.9195 - val_loss: 0.5451 - val_accuracy: 0.8126\n",
            "Epoch 6/8\n",
            "27/27 [==============================] - 3s 122ms/step - loss: 0.1539 - accuracy: 0.9433 - val_loss: 0.4952 - val_accuracy: 0.8206\n",
            "Epoch 7/8\n",
            "27/27 [==============================] - 3s 120ms/step - loss: 0.1274 - accuracy: 0.9552 - val_loss: 0.4587 - val_accuracy: 0.8221\n",
            "Epoch 8/8\n",
            "27/27 [==============================] - 3s 120ms/step - loss: 0.0974 - accuracy: 0.9650 - val_loss: 0.4212 - val_accuracy: 0.8409\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 8ms/step - loss: 0.3895 - accuracy: 0.8525\n",
            "Accuracy :   0.8524705767631531\n",
            "\n",
            "\n",
            "2 of KFold 5\n",
            "Epoch 1/8\n",
            "27/27 [==============================] - 4s 156ms/step - loss: 0.9889 - accuracy: 0.5362 - val_loss: 1.0243 - val_accuracy: 0.4674\n",
            "Epoch 2/8\n",
            "27/27 [==============================] - 3s 118ms/step - loss: 0.6606 - accuracy: 0.7266 - val_loss: 0.9156 - val_accuracy: 0.5912\n",
            "Epoch 3/8\n",
            "27/27 [==============================] - 3s 119ms/step - loss: 0.4416 - accuracy: 0.8278 - val_loss: 0.7885 - val_accuracy: 0.6771\n",
            "Epoch 4/8\n",
            "27/27 [==============================] - 3s 119ms/step - loss: 0.2946 - accuracy: 0.8863 - val_loss: 0.6376 - val_accuracy: 0.7724\n",
            "Epoch 5/8\n",
            "27/27 [==============================] - 3s 118ms/step - loss: 0.2155 - accuracy: 0.9193 - val_loss: 0.5436 - val_accuracy: 0.8147\n",
            "Epoch 6/8\n",
            "27/27 [==============================] - 3s 116ms/step - loss: 0.1660 - accuracy: 0.9390 - val_loss: 0.4522 - val_accuracy: 0.8388\n",
            "Epoch 7/8\n",
            "27/27 [==============================] - 3s 119ms/step - loss: 0.1219 - accuracy: 0.9557 - val_loss: 0.4456 - val_accuracy: 0.8232\n",
            "Epoch 8/8\n",
            "27/27 [==============================] - 3s 116ms/step - loss: 0.1044 - accuracy: 0.9623 - val_loss: 0.4372 - val_accuracy: 0.8385\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 8ms/step - loss: 0.4014 - accuracy: 0.8501\n",
            "Accuracy :   0.8500823974609375\n",
            "\n",
            "\n",
            "3 of KFold 5\n",
            "Epoch 1/8\n",
            "27/27 [==============================] - 4s 157ms/step - loss: 0.9578 - accuracy: 0.5564 - val_loss: 1.0200 - val_accuracy: 0.4626\n",
            "Epoch 2/8\n",
            "27/27 [==============================] - 3s 117ms/step - loss: 0.6398 - accuracy: 0.7405 - val_loss: 0.9170 - val_accuracy: 0.6144\n",
            "Epoch 3/8\n",
            "27/27 [==============================] - 3s 116ms/step - loss: 0.4420 - accuracy: 0.8278 - val_loss: 0.8054 - val_accuracy: 0.7594\n",
            "Epoch 4/8\n",
            "27/27 [==============================] - 3s 118ms/step - loss: 0.3042 - accuracy: 0.8839 - val_loss: 0.6328 - val_accuracy: 0.8141\n",
            "Epoch 5/8\n",
            "27/27 [==============================] - 3s 119ms/step - loss: 0.2170 - accuracy: 0.9201 - val_loss: 0.5419 - val_accuracy: 0.8197\n",
            "Epoch 6/8\n",
            "27/27 [==============================] - 3s 118ms/step - loss: 0.1641 - accuracy: 0.9412 - val_loss: 0.4578 - val_accuracy: 0.8385\n",
            "Epoch 7/8\n",
            "27/27 [==============================] - 3s 117ms/step - loss: 0.1258 - accuracy: 0.9545 - val_loss: 0.4366 - val_accuracy: 0.8388\n",
            "Epoch 8/8\n",
            "27/27 [==============================] - 3s 119ms/step - loss: 0.1002 - accuracy: 0.9653 - val_loss: 0.4345 - val_accuracy: 0.8400\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 7ms/step - loss: 0.4089 - accuracy: 0.8397\n",
            "Accuracy :   0.839726984500885\n",
            "\n",
            "\n",
            "4 of KFold 5\n",
            "Epoch 1/8\n",
            "27/27 [==============================] - 4s 160ms/step - loss: 0.9782 - accuracy: 0.5401 - val_loss: 1.0261 - val_accuracy: 0.4529\n",
            "Epoch 2/8\n",
            "27/27 [==============================] - 3s 121ms/step - loss: 0.6662 - accuracy: 0.7250 - val_loss: 0.9304 - val_accuracy: 0.5638\n",
            "Epoch 3/8\n",
            "27/27 [==============================] - 3s 121ms/step - loss: 0.4370 - accuracy: 0.8300 - val_loss: 0.8132 - val_accuracy: 0.6797\n",
            "Epoch 4/8\n",
            "27/27 [==============================] - 3s 120ms/step - loss: 0.3031 - accuracy: 0.8862 - val_loss: 0.6579 - val_accuracy: 0.8138\n",
            "Epoch 5/8\n",
            "27/27 [==============================] - 3s 118ms/step - loss: 0.2156 - accuracy: 0.9213 - val_loss: 0.5804 - val_accuracy: 0.7859\n",
            "Epoch 6/8\n",
            "27/27 [==============================] - 3s 119ms/step - loss: 0.1542 - accuracy: 0.9458 - val_loss: 0.4750 - val_accuracy: 0.8326\n",
            "Epoch 7/8\n",
            "27/27 [==============================] - 3s 119ms/step - loss: 0.1228 - accuracy: 0.9564 - val_loss: 0.4455 - val_accuracy: 0.8347\n",
            "Epoch 8/8\n",
            "27/27 [==============================] - 3s 119ms/step - loss: 0.0960 - accuracy: 0.9646 - val_loss: 0.4294 - val_accuracy: 0.8371\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 7ms/step - loss: 0.3961 - accuracy: 0.8498\n",
            "Accuracy :   0.8498470187187195\n",
            "\n",
            "\n",
            "5 of KFold 5\n",
            "Epoch 1/8\n",
            "27/27 [==============================] - 4s 163ms/step - loss: 0.9907 - accuracy: 0.5383 - val_loss: 1.0322 - val_accuracy: 0.4476\n",
            "Epoch 2/8\n",
            "27/27 [==============================] - 3s 119ms/step - loss: 0.6627 - accuracy: 0.7260 - val_loss: 0.9038 - val_accuracy: 0.6700\n",
            "Epoch 3/8\n",
            "27/27 [==============================] - 3s 116ms/step - loss: 0.4312 - accuracy: 0.8325 - val_loss: 0.7401 - val_accuracy: 0.7785\n",
            "Epoch 4/8\n",
            "27/27 [==============================] - 3s 117ms/step - loss: 0.2944 - accuracy: 0.8900 - val_loss: 0.6135 - val_accuracy: 0.8179\n",
            "Epoch 5/8\n",
            "27/27 [==============================] - 3s 117ms/step - loss: 0.2039 - accuracy: 0.9248 - val_loss: 0.5156 - val_accuracy: 0.8374\n",
            "Epoch 6/8\n",
            "27/27 [==============================] - 3s 118ms/step - loss: 0.1515 - accuracy: 0.9440 - val_loss: 0.4365 - val_accuracy: 0.8438\n",
            "Epoch 7/8\n",
            "27/27 [==============================] - 3s 117ms/step - loss: 0.1281 - accuracy: 0.9542 - val_loss: 0.4281 - val_accuracy: 0.8424\n",
            "Epoch 8/8\n",
            "27/27 [==============================] - 3s 117ms/step - loss: 0.0980 - accuracy: 0.9655 - val_loss: 0.4047 - val_accuracy: 0.8479\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 7ms/step - loss: 0.4219 - accuracy: 0.8414\n",
            "Accuracy :   0.8413744568824768\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXMFBJO0zQld",
        "colab_type": "code",
        "outputId": "65415a90-04e4-469a-dd93-32d437e8e50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "pred = model_1.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test.argmax(1),pred.argmax(1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85      2116\n",
            "           1       0.85      0.87      0.86      1535\n",
            "           2       0.88      0.82      0.85      1661\n",
            "\n",
            "    accuracy                           0.85      5312\n",
            "   macro avg       0.85      0.85      0.85      5312\n",
            "weighted avg       0.85      0.85      0.85      5312\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmhX-AGTXLIs",
        "colab_type": "text"
      },
      "source": [
        " **By stacking LSTM models , it got an accuracy of 85%!! Already outperforming the MultinomialNB()** \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "### Since the training data set is small , it is preferred to put trainable = False, Let's see what happens if trainable=True\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY1MjwWWMkC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_true():\n",
        "\n",
        "  inp = Input(shape=(max_len,))\n",
        "  x = Embedding(vocab_len+1, 300, weights=[embedding_matrix_weights], trainable=True)(inp)\n",
        "  x = SpatialDropout1D(0.3)(x)\n",
        "  x1 = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
        "  x2 = Bidirectional(GRU(128, return_sequences=True))(x1)\n",
        "  max_pool1 = GlobalMaxPool1D()(x1)\n",
        "  max_pool2 = GlobalMaxPool1D()(x2)\n",
        "  conc = concatenate([max_pool1, max_pool2])\n",
        "  x = Dense(128,activation='relu')(conc)\n",
        "  x = Dropout(0.5)(x)\n",
        "  predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "  model = Model(inputs=inp, outputs=predictions)\n",
        "  callbacks = EarlyStopping(monitor='val_loss',patience=3)\n",
        "\n",
        "  from tensorflow.keras.optimizers import Adam,RMSprop\n",
        "  adam = Adam()\n",
        "  model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPJ0c97XCfn2",
        "colab_type": "code",
        "outputId": "aaa129ae-ad26-4ce7-ede5-caf1a7a3c28e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold=StratifiedKFold(n_splits=5,shuffle=True)\n",
        "score=[]\n",
        "i=1\n",
        "for train_index , test_index in kfold.split(X_train,y_train.argmax(1)):\n",
        "    print('{} of KFold {}'.format(i,kfold.n_splits))\n",
        "    X_train_main,X_val = X_train[train_index],X_train[test_index]\n",
        "    y_train_main,y_val = y_train[train_index],y_train[test_index]\n",
        "    model_2nd = model_true()\n",
        "    history = model_2nd.fit(X_train_main,y_train_main,epochs=5,batch_size=128,validation_split=0.2)\n",
        "    print('\\n')\n",
        "    acc = model_2nd.evaluate(X_val,y_val)\n",
        "    score.append(acc[1])\n",
        "    print('Accuracy:  ',acc[1])\n",
        "    i+=1\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 of KFold 5\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 11s 105ms/step - loss: 0.7899 - accuracy: 0.6523 - val_loss: 0.5648 - val_accuracy: 0.7668\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 10s 94ms/step - loss: 0.4327 - accuracy: 0.8359 - val_loss: 0.4416 - val_accuracy: 0.8232\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 10s 93ms/step - loss: 0.2744 - accuracy: 0.8993 - val_loss: 0.4379 - val_accuracy: 0.8321\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 10s 93ms/step - loss: 0.1774 - accuracy: 0.9363 - val_loss: 0.4527 - val_accuracy: 0.8488\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 10s 93ms/step - loss: 0.1208 - accuracy: 0.9573 - val_loss: 0.5158 - val_accuracy: 0.8468\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 0.5286 - accuracy: 0.8405\n",
            "Accuracy:   0.8404706120491028\n",
            "2 of KFold 5\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 11s 101ms/step - loss: 0.7981 - accuracy: 0.6396 - val_loss: 0.6080 - val_accuracy: 0.7459\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 10s 89ms/step - loss: 0.4378 - accuracy: 0.8308 - val_loss: 0.4601 - val_accuracy: 0.8244\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 10s 90ms/step - loss: 0.2656 - accuracy: 0.9018 - val_loss: 0.4349 - val_accuracy: 0.8421\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 10s 90ms/step - loss: 0.1808 - accuracy: 0.9334 - val_loss: 0.5234 - val_accuracy: 0.8341\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 10s 89ms/step - loss: 0.1242 - accuracy: 0.9547 - val_loss: 0.5009 - val_accuracy: 0.8494\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 0.4784 - accuracy: 0.8475\n",
            "Accuracy:   0.8474935293197632\n",
            "3 of KFold 5\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 11s 102ms/step - loss: 0.8128 - accuracy: 0.6421 - val_loss: 0.5794 - val_accuracy: 0.7665\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 10s 93ms/step - loss: 0.4494 - accuracy: 0.8285 - val_loss: 0.4807 - val_accuracy: 0.8144\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 10s 95ms/step - loss: 0.2733 - accuracy: 0.9003 - val_loss: 0.4509 - val_accuracy: 0.8318\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 10s 93ms/step - loss: 0.1714 - accuracy: 0.9369 - val_loss: 0.4682 - val_accuracy: 0.8403\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 10s 95ms/step - loss: 0.1234 - accuracy: 0.9572 - val_loss: 0.5493 - val_accuracy: 0.8435\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 0.4620 - accuracy: 0.8593\n",
            "Accuracy:   0.8592609763145447\n",
            "4 of KFold 5\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 11s 104ms/step - loss: 0.8019 - accuracy: 0.6423 - val_loss: 0.5443 - val_accuracy: 0.7791\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 10s 95ms/step - loss: 0.4415 - accuracy: 0.8328 - val_loss: 0.4423 - val_accuracy: 0.8303\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 10s 96ms/step - loss: 0.2753 - accuracy: 0.9013 - val_loss: 0.4241 - val_accuracy: 0.8397\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 10s 95ms/step - loss: 0.1776 - accuracy: 0.9361 - val_loss: 0.4510 - val_accuracy: 0.8471\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 10s 95ms/step - loss: 0.1237 - accuracy: 0.9564 - val_loss: 0.4859 - val_accuracy: 0.8488\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 9ms/step - loss: 0.4643 - accuracy: 0.8593\n",
            "Accuracy:   0.8592609763145447\n",
            "5 of KFold 5\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 11s 104ms/step - loss: 0.7960 - accuracy: 0.6457 - val_loss: 0.5684 - val_accuracy: 0.7665\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 10s 96ms/step - loss: 0.4333 - accuracy: 0.8336 - val_loss: 0.4553 - val_accuracy: 0.8256\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 10s 95ms/step - loss: 0.2680 - accuracy: 0.9041 - val_loss: 0.4412 - val_accuracy: 0.8432\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 10s 95ms/step - loss: 0.1761 - accuracy: 0.9359 - val_loss: 0.4762 - val_accuracy: 0.8474\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 10s 96ms/step - loss: 0.1241 - accuracy: 0.9557 - val_loss: 0.5001 - val_accuracy: 0.8453\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 10ms/step - loss: 0.4843 - accuracy: 0.8506\n",
            "Accuracy:   0.8505530953407288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfzlHA0zUSaA",
        "colab_type": "code",
        "outputId": "7bc6143d-ba95-492a-ae1a-aa33bcfb5d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Accuracy :  ',np.mean(score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :   0.8514078378677368\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AajUF8Yo17wv",
        "colab_type": "code",
        "outputId": "22000eb1-bd60-4e77-b255-05b30eb0a87e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "pred_2 = model_2nd.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test.argmax(1),pred_2.argmax(1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.82      0.85      2116\n",
            "           1       0.84      0.87      0.85      1535\n",
            "           2       0.84      0.87      0.85      1661\n",
            "\n",
            "    accuracy                           0.85      5312\n",
            "   macro avg       0.85      0.85      0.85      5312\n",
            "weighted avg       0.85      0.85      0.85      5312\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx4-NAMZt5FM",
        "colab_type": "text"
      },
      "source": [
        "### **Nice! The new complex performs the same as our previous model with an accuracy of 85, and it seems that the recall of some of the classes are better too!!! Let's see if any models can outperform this.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-XGZ5WOuk_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Instead of concatenating the embeddings through axis=0 , lets try concatenating them through axis =1\n",
        "\n",
        "embedding_axis1 = np.concatenate((embedding_matrix1,embedding_matrix2),axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL60OkJlenDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_3():\n",
        "\n",
        "  sequence_input = Input(shape=(max_len,))\n",
        "  embedding_layer = Embedding(vocab_len+1,600,weights = [embedding_axis1],trainable = True,input_length=max_len)\n",
        "  x = embedding_layer(sequence_input)\n",
        "  x = SpatialDropout1D(0.2)(x)\n",
        "  x = Bidirectional(LSTM(128,return_sequences=True))(x)\n",
        "  x = Conv1D(64,kernel_size=2,padding='valid',kernel_initializer=\"he_uniform\")(x)\n",
        "  avg_pool = GlobalAvgPool1D()(x)\n",
        "  max_pool = GlobalMaxPool1D()(x)\n",
        "  x = concatenate([avg_pool,max_pool])\n",
        "  x = Dense(128,activation='relu')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  pred = Dense(3,activation='softmax')(x)\n",
        "\n",
        "  model_3 = Model(sequence_input, pred)\n",
        "  model_3.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model_3\n",
        "\n",
        "\n",
        "#callbacks = EarlyStopping(monitor='val_loss',patience=3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "628Dii52qrrY",
        "colab_type": "code",
        "outputId": "d7b7f98f-4bd0-481a-8d31-79fbe81d6c49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold=StratifiedKFold(n_splits=5,shuffle=True)\n",
        "i=1\n",
        "score=[]\n",
        "for train_index , test_index in kfold.split(X_train,y_train.argmax(1)):\n",
        "    print('{} of KFold {}'.format(i,kfold.n_splits))\n",
        "    X_train_main,X_val = X_train[train_index],X_train[test_index]\n",
        "    y_train_main,y_val = y_train[train_index],y_train[test_index]\n",
        "    model_3rd = model_3()\n",
        "    history = model_3rd.fit(X_train_main,y_train_main,epochs=5,batch_size=512,validation_split=0.2)\n",
        "    print('\\n')\n",
        "    acc = model_3rd.evaluate(X_val,y_val)\n",
        "    score.append(acc[1])\n",
        "    print('\\n')\n",
        "    print('Accuracy:  ',acc[1])\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 of KFold 5\n",
            "Epoch 1/5\n",
            "27/27 [==============================] - 4s 165ms/step - loss: 0.9326 - accuracy: 0.5502 - val_loss: 0.7535 - val_accuracy: 0.6800\n",
            "Epoch 2/5\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.6162 - accuracy: 0.7562 - val_loss: 0.5338 - val_accuracy: 0.7859\n",
            "Epoch 3/5\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.4302 - accuracy: 0.8371 - val_loss: 0.6169 - val_accuracy: 0.7721\n",
            "Epoch 4/5\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.2950 - accuracy: 0.8898 - val_loss: 0.4736 - val_accuracy: 0.8206\n",
            "Epoch 5/5\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.2108 - accuracy: 0.9248 - val_loss: 0.4938 - val_accuracy: 0.8285\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 6ms/step - loss: 0.4335 - accuracy: 0.8426\n",
            "\n",
            "\n",
            "Accuracy:   0.8425882458686829\n",
            "2 of KFold 5\n",
            "Epoch 1/5\n",
            "27/27 [==============================] - 4s 160ms/step - loss: 0.9138 - accuracy: 0.5636 - val_loss: 0.6989 - val_accuracy: 0.6900\n",
            "Epoch 2/5\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.5991 - accuracy: 0.7619 - val_loss: 0.5362 - val_accuracy: 0.7785\n",
            "Epoch 3/5\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.4126 - accuracy: 0.8442 - val_loss: 0.5242 - val_accuracy: 0.7915\n",
            "Epoch 4/5\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.2925 - accuracy: 0.8897 - val_loss: 0.4243 - val_accuracy: 0.8362\n",
            "Epoch 5/5\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.2076 - accuracy: 0.9252 - val_loss: 0.4508 - val_accuracy: 0.8429\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 6ms/step - loss: 0.4462 - accuracy: 0.8473\n",
            "\n",
            "\n",
            "Accuracy:   0.8472581505775452\n",
            "3 of KFold 5\n",
            "Epoch 1/5\n",
            "27/27 [==============================] - 5s 174ms/step - loss: 0.9053 - accuracy: 0.5781 - val_loss: 0.8595 - val_accuracy: 0.6265\n",
            "Epoch 2/5\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.5995 - accuracy: 0.7584 - val_loss: 0.5146 - val_accuracy: 0.7976\n",
            "Epoch 3/5\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.4144 - accuracy: 0.8395 - val_loss: 0.5307 - val_accuracy: 0.7826\n",
            "Epoch 4/5\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.2865 - accuracy: 0.8943 - val_loss: 0.4461 - val_accuracy: 0.8309\n",
            "Epoch 5/5\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.2075 - accuracy: 0.9247 - val_loss: 0.4680 - val_accuracy: 0.8438\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 6ms/step - loss: 0.4707 - accuracy: 0.8407\n",
            "\n",
            "\n",
            "Accuracy:   0.8406683802604675\n",
            "4 of KFold 5\n",
            "Epoch 1/5\n",
            "27/27 [==============================] - 4s 156ms/step - loss: 0.9089 - accuracy: 0.5748 - val_loss: 0.7216 - val_accuracy: 0.6965\n",
            "Epoch 2/5\n",
            "27/27 [==============================] - 4s 132ms/step - loss: 0.5965 - accuracy: 0.7598 - val_loss: 0.5580 - val_accuracy: 0.7788\n",
            "Epoch 3/5\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.4162 - accuracy: 0.8410 - val_loss: 0.5138 - val_accuracy: 0.7971\n",
            "Epoch 4/5\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.2841 - accuracy: 0.8966 - val_loss: 0.4247 - val_accuracy: 0.8429\n",
            "Epoch 5/5\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.2198 - accuracy: 0.9215 - val_loss: 0.4250 - val_accuracy: 0.8474\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 6ms/step - loss: 0.4004 - accuracy: 0.8583\n",
            "\n",
            "\n",
            "Accuracy:   0.8583195805549622\n",
            "5 of KFold 5\n",
            "Epoch 1/5\n",
            "27/27 [==============================] - 4s 153ms/step - loss: 0.9183 - accuracy: 0.5706 - val_loss: 0.7557 - val_accuracy: 0.6753\n",
            "Epoch 2/5\n",
            "27/27 [==============================] - 4s 132ms/step - loss: 0.6063 - accuracy: 0.7585 - val_loss: 0.5752 - val_accuracy: 0.7638\n",
            "Epoch 3/5\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.4248 - accuracy: 0.8383 - val_loss: 0.4926 - val_accuracy: 0.8062\n",
            "Epoch 4/5\n",
            "27/27 [==============================] - 4s 131ms/step - loss: 0.2838 - accuracy: 0.8957 - val_loss: 0.4513 - val_accuracy: 0.8318\n",
            "Epoch 5/5\n",
            "27/27 [==============================] - 4s 132ms/step - loss: 0.2165 - accuracy: 0.9181 - val_loss: 0.5064 - val_accuracy: 0.8332\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 6ms/step - loss: 0.5151 - accuracy: 0.8273\n",
            "\n",
            "\n",
            "Accuracy:   0.8272534608840942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkPqdIO_ygH8",
        "colab_type": "code",
        "outputId": "3db41c32-b932-45a3-d1b4-61b18e9cf3a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Accuracy:  ',np.mean(score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:   0.8432175636291503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_do75yiA3OJa",
        "colab_type": "code",
        "outputId": "f26ddb72-602b-4a73-8fda-90069eccdb6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "pred_3 = model_3rd.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test.argmax(1),pred_3.argmax(1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.93      0.83      2116\n",
            "           1       0.92      0.77      0.84      1535\n",
            "           2       0.90      0.76      0.82      1661\n",
            "\n",
            "    accuracy                           0.83      5312\n",
            "   macro avg       0.86      0.82      0.83      5312\n",
            "weighted avg       0.85      0.83      0.83      5312\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve6O4ai4yo8b",
        "colab_type": "text"
      },
      "source": [
        "### **Yikes ! The accuracy decreased to 83%.!**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akHDbfYHzrRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_4():\n",
        "\n",
        "  input_sequence = Input(shape=(max_len,))\n",
        "  embedding_layer = Embedding(vocab_len+1,600,weights=[embedding_axis1],trainable=True)\n",
        "  x = embedding_layer(input_sequence)\n",
        "  x = SpatialDropout1D(0.2)(x)\n",
        "  x1 = Bidirectional(GRU(128,return_sequences=True))(x)\n",
        "  x2 = Bidirectional(GRU(64,return_sequences=True))(x1)\n",
        "  max_pool1 = GlobalMaxPool1D()(x1)\n",
        "  max_pool2 = GlobalMaxPool1D()(x2)\n",
        "  conc = concatenate([max_pool1, max_pool2])\n",
        "  x = Dense(128,activation='relu')(conc)\n",
        "  x = BatchNormalization()(x)\n",
        "  pred = Dense(3,activation='softmax')(x)\n",
        "\n",
        "  model_4 = Model(input_sequence,pred)\n",
        "  model_4.compile(optimizer = 'adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model_4\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hehen_D60ILm",
        "colab_type": "code",
        "outputId": "4843f336-656b-4324-a431-a2189101322b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold=StratifiedKFold(n_splits=5,shuffle=True)\n",
        "i=1\n",
        "score=[]\n",
        "for train_index , test_index in kfold.split(X_train,y_train.argmax(1)):\n",
        "    print('{} of KFold {}'.format(i,kfold.n_splits))\n",
        "    X_train_main,X_val = X_train[train_index],X_train[test_index]\n",
        "    y_train_main,y_val = y_train[train_index],y_train[test_index]\n",
        "    model_4th = model_4()\n",
        "    history = model_4th.fit(X_train_main,y_train_main,epochs=5,batch_size=512,validation_split=0.2)\n",
        "    print('\\n')\n",
        "    acc = model_4th.evaluate(X_val,y_val)\n",
        "    score.append(acc[1])\n",
        "    print('\\n')\n",
        "    print('Accuracy:  ',acc[1])\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 of KFold 5\n",
            "Epoch 1/5\n",
            "27/27 [==============================] - 7s 241ms/step - loss: 0.8675 - accuracy: 0.6211 - val_loss: 0.9154 - val_accuracy: 0.7168\n",
            "Epoch 2/5\n",
            "27/27 [==============================] - 5s 201ms/step - loss: 0.5030 - accuracy: 0.8037 - val_loss: 0.7987 - val_accuracy: 0.7576\n",
            "Epoch 3/5\n",
            "27/27 [==============================] - 5s 199ms/step - loss: 0.2917 - accuracy: 0.8941 - val_loss: 0.6689 - val_accuracy: 0.7774\n",
            "Epoch 4/5\n",
            "27/27 [==============================] - 5s 201ms/step - loss: 0.1641 - accuracy: 0.9442 - val_loss: 0.5442 - val_accuracy: 0.8238\n",
            "Epoch 5/5\n",
            "27/27 [==============================] - 5s 198ms/step - loss: 0.0982 - accuracy: 0.9675 - val_loss: 0.4885 - val_accuracy: 0.8303\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 8ms/step - loss: 0.4860 - accuracy: 0.8304\n",
            "\n",
            "\n",
            "Accuracy:   0.8303529620170593\n",
            "2 of KFold 5\n",
            "Epoch 1/5\n",
            "27/27 [==============================] - 6s 234ms/step - loss: 0.8362 - accuracy: 0.6340 - val_loss: 0.9218 - val_accuracy: 0.6612\n",
            "Epoch 2/5\n",
            "27/27 [==============================] - 5s 196ms/step - loss: 0.4795 - accuracy: 0.8110 - val_loss: 0.7613 - val_accuracy: 0.7747\n",
            "Epoch 3/5\n",
            "27/27 [==============================] - 5s 198ms/step - loss: 0.2675 - accuracy: 0.9027 - val_loss: 0.6294 - val_accuracy: 0.7953\n",
            "Epoch 4/5\n",
            "27/27 [==============================] - 5s 199ms/step - loss: 0.1551 - accuracy: 0.9463 - val_loss: 0.5875 - val_accuracy: 0.7491\n",
            "Epoch 5/5\n",
            "27/27 [==============================] - 5s 199ms/step - loss: 0.0883 - accuracy: 0.9721 - val_loss: 0.4943 - val_accuracy: 0.8071\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 8ms/step - loss: 0.5036 - accuracy: 0.8089\n",
            "\n",
            "\n",
            "Accuracy:   0.8088961839675903\n",
            "3 of KFold 5\n",
            "Epoch 1/5\n",
            "27/27 [==============================] - 6s 235ms/step - loss: 0.8620 - accuracy: 0.6152 - val_loss: 0.9143 - val_accuracy: 0.7288\n",
            "Epoch 2/5\n",
            "27/27 [==============================] - 5s 194ms/step - loss: 0.5011 - accuracy: 0.8028 - val_loss: 0.7828 - val_accuracy: 0.7668\n",
            "Epoch 3/5\n",
            "27/27 [==============================] - 5s 197ms/step - loss: 0.2868 - accuracy: 0.8952 - val_loss: 0.6425 - val_accuracy: 0.8188\n",
            "Epoch 4/5\n",
            "27/27 [==============================] - 5s 198ms/step - loss: 0.1554 - accuracy: 0.9456 - val_loss: 0.5809 - val_accuracy: 0.7738\n",
            "Epoch 5/5\n",
            "27/27 [==============================] - 5s 196ms/step - loss: 0.0921 - accuracy: 0.9709 - val_loss: 0.4672 - val_accuracy: 0.8376\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 8ms/step - loss: 0.4483 - accuracy: 0.8494\n",
            "\n",
            "\n",
            "Accuracy:   0.8493763208389282\n",
            "4 of KFold 5\n",
            "Epoch 1/5\n",
            "27/27 [==============================] - 6s 236ms/step - loss: 0.8466 - accuracy: 0.6312 - val_loss: 0.9110 - val_accuracy: 0.7065\n",
            "Epoch 2/5\n",
            "27/27 [==============================] - 5s 199ms/step - loss: 0.4883 - accuracy: 0.8091 - val_loss: 0.7692 - val_accuracy: 0.7765\n",
            "Epoch 3/5\n",
            "27/27 [==============================] - 5s 198ms/step - loss: 0.2780 - accuracy: 0.9009 - val_loss: 0.6455 - val_accuracy: 0.7944\n",
            "Epoch 4/5\n",
            "27/27 [==============================] - 5s 198ms/step - loss: 0.1520 - accuracy: 0.9469 - val_loss: 0.5405 - val_accuracy: 0.8406\n",
            "Epoch 5/5\n",
            "27/27 [==============================] - 5s 197ms/step - loss: 0.0883 - accuracy: 0.9706 - val_loss: 0.4513 - val_accuracy: 0.8474\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 8ms/step - loss: 0.4377 - accuracy: 0.8560\n",
            "\n",
            "\n",
            "Accuracy:   0.8559660911560059\n",
            "5 of KFold 5\n",
            "Epoch 1/5\n",
            "27/27 [==============================] - 6s 226ms/step - loss: 0.8691 - accuracy: 0.6144 - val_loss: 0.9107 - val_accuracy: 0.7218\n",
            "Epoch 2/5\n",
            "27/27 [==============================] - 5s 197ms/step - loss: 0.5004 - accuracy: 0.8044 - val_loss: 0.7785 - val_accuracy: 0.7812\n",
            "Epoch 3/5\n",
            "27/27 [==============================] - 5s 198ms/step - loss: 0.2892 - accuracy: 0.8942 - val_loss: 0.6560 - val_accuracy: 0.7941\n",
            "Epoch 4/5\n",
            "27/27 [==============================] - 5s 195ms/step - loss: 0.1575 - accuracy: 0.9469 - val_loss: 0.5804 - val_accuracy: 0.7618\n",
            "Epoch 5/5\n",
            "27/27 [==============================] - 5s 198ms/step - loss: 0.0955 - accuracy: 0.9695 - val_loss: 0.4859 - val_accuracy: 0.8156\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 8ms/step - loss: 0.4915 - accuracy: 0.8117\n",
            "\n",
            "\n",
            "Accuracy:   0.8117204308509827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MvY3LK40uQx",
        "colab_type": "code",
        "outputId": "b4f2e516-53bb-4ed0-8973-3ff080a5832c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Accuracy:  ',np.mean(score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:   0.8312623977661133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPq7OUCw4Lgn",
        "colab_type": "code",
        "outputId": "da1fa61e-ce5f-44f6-c060-fe664b3476d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "pred_4 = model_4th.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test.argmax(1),pred_4.argmax(1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.96      0.82      2116\n",
            "           1       0.94      0.74      0.83      1535\n",
            "           2       0.93      0.70      0.80      1661\n",
            "\n",
            "    accuracy                           0.82      5312\n",
            "   macro avg       0.86      0.80      0.82      5312\n",
            "weighted avg       0.85      0.82      0.82      5312\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sjhFLQ50uxv",
        "colab_type": "text"
      },
      "source": [
        "### **The accuracy decreased . Let's try one more model!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EtAaHlT0vTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_5():\n",
        "\n",
        "  inp = Input(shape=(max_len,))\n",
        "  embedding_layer = Embedding(vocab_len+1,600,weights=[embedding_axis1],trainable=True)\n",
        "  x = embedding_layer(inp)\n",
        "  x = SpatialDropout1D(0.2)(x)\n",
        "  x1 = Bidirectional(LSTM(64,return_sequences=True))(x)\n",
        "  x1 = Conv1D(64 ,kernel_size=3,padding='same',activation='linear')(x1)\n",
        "  x1 = BatchNormalization()(x1)\n",
        "  x1 = Conv1D(64,kernel_size=3,padding='same',activation='linear')(x1)\n",
        "  x1 = BatchNormalization()(x1)\n",
        "  x2 = Conv1D(64,kernel_size=1,padding='same',activation='linear')(x)\n",
        "  xmain = concatenate([x1,x2])\n",
        "  xmain1 = Conv1D(64,kernel_size=3,padding='same',activation='linear')(xmain)\n",
        "  xmain1 = BatchNormalization()(xmain1)\n",
        "  xmain1 = Conv1D(64,kernel_size=3,padding='same',activation='linear')(xmain1)\n",
        "  xmain1 = BatchNormalization()(xmain1)\n",
        "  x = concatenate([xmain,xmain1])\n",
        "  x = GlobalMaxPool1D()(x)\n",
        "  x = Dense(182,activation='relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = Dense(3,activation = 'softmax')(x)\n",
        "\n",
        "  model_last = Model(inp,x)\n",
        "  model_last.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model_last"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nKnYGUc2FTl",
        "colab_type": "code",
        "outputId": "83fc8c9e-ab7b-4176-cc37-61db059d2ce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "kfold=StratifiedKFold(n_splits=5,shuffle=True)\n",
        "i=1\n",
        "score=[]\n",
        "for train_index , test_index in kfold.split(X_train,y_train.argmax(1)):\n",
        "    print('{} of KFold {}'.format(i,kfold.n_splits))\n",
        "    X_train_main,X_val = X_train[train_index],X_train[test_index]\n",
        "    y_train_main,y_val = y_train[train_index],y_train[test_index]\n",
        "    model_5th = model_5()\n",
        "    history = model_5th.fit(X_train_main,y_train_main,epochs=5,batch_size=128,validation_split=0.2)\n",
        "    print('\\n')\n",
        "    acc = model_5th.evaluate(X_val,y_val)\n",
        "    score.append(acc[1])\n",
        "    print('\\n')\n",
        "    print('Accuracy:  ',acc[1])\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 of KFold 5\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 16s 147ms/step - loss: 1.0765 - accuracy: 0.5652 - val_loss: 0.8043 - val_accuracy: 0.6918\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 15s 137ms/step - loss: 0.5298 - accuracy: 0.7895 - val_loss: 0.7112 - val_accuracy: 0.7062\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 15s 136ms/step - loss: 0.2708 - accuracy: 0.8968 - val_loss: 0.6875 - val_accuracy: 0.7474\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 15s 137ms/step - loss: 0.1557 - accuracy: 0.9420 - val_loss: 0.4682 - val_accuracy: 0.8335\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 15s 139ms/step - loss: 0.1053 - accuracy: 0.9609 - val_loss: 0.6896 - val_accuracy: 0.8071\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 6ms/step - loss: 0.6532 - accuracy: 0.8144\n",
            "\n",
            "\n",
            "Accuracy:   0.8143529295921326\n",
            "2 of KFold 5\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 16s 146ms/step - loss: 1.0476 - accuracy: 0.5716 - val_loss: 0.8550 - val_accuracy: 0.5747\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 15s 137ms/step - loss: 0.5309 - accuracy: 0.7898 - val_loss: 0.6784 - val_accuracy: 0.6871\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 15s 138ms/step - loss: 0.2796 - accuracy: 0.8973 - val_loss: 0.5505 - val_accuracy: 0.7724\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 15s 138ms/step - loss: 0.1563 - accuracy: 0.9437 - val_loss: 0.4655 - val_accuracy: 0.8403\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 15s 138ms/step - loss: 0.1028 - accuracy: 0.9638 - val_loss: 0.4786 - val_accuracy: 0.8479\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 7ms/step - loss: 0.4619 - accuracy: 0.8555\n",
            "\n",
            "\n",
            "Accuracy:   0.8554953932762146\n",
            "3 of KFold 5\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 15s 143ms/step - loss: 1.0371 - accuracy: 0.5757 - val_loss: 0.8134 - val_accuracy: 0.6912\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 15s 138ms/step - loss: 0.5145 - accuracy: 0.7950 - val_loss: 0.6653 - val_accuracy: 0.7218\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 15s 136ms/step - loss: 0.2677 - accuracy: 0.8998 - val_loss: 0.4225 - val_accuracy: 0.8347\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 15s 137ms/step - loss: 0.1462 - accuracy: 0.9470 - val_loss: 0.4922 - val_accuracy: 0.8309\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 15s 138ms/step - loss: 0.0999 - accuracy: 0.9671 - val_loss: 0.5225 - val_accuracy: 0.8297\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 6ms/step - loss: 0.4843 - accuracy: 0.8428\n",
            "\n",
            "\n",
            "Accuracy:   0.8427865505218506\n",
            "4 of KFold 5\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 15s 143ms/step - loss: 1.0483 - accuracy: 0.5776 - val_loss: 0.8220 - val_accuracy: 0.6185\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 15s 136ms/step - loss: 0.5095 - accuracy: 0.7998 - val_loss: 0.5810 - val_accuracy: 0.7662\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 15s 138ms/step - loss: 0.2670 - accuracy: 0.9008 - val_loss: 0.4273 - val_accuracy: 0.8329\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 15s 136ms/step - loss: 0.1602 - accuracy: 0.9422 - val_loss: 0.4262 - val_accuracy: 0.8429\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 15s 137ms/step - loss: 0.0989 - accuracy: 0.9653 - val_loss: 0.5718 - val_accuracy: 0.8279\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 6ms/step - loss: 0.5179 - accuracy: 0.8428\n",
            "\n",
            "\n",
            "Accuracy:   0.8427865505218506\n",
            "5 of KFold 5\n",
            "Epoch 1/5\n",
            "107/107 [==============================] - 15s 142ms/step - loss: 1.0771 - accuracy: 0.5660 - val_loss: 0.8762 - val_accuracy: 0.5312\n",
            "Epoch 2/5\n",
            "107/107 [==============================] - 14s 135ms/step - loss: 0.5395 - accuracy: 0.7877 - val_loss: 0.6009 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "107/107 [==============================] - 14s 135ms/step - loss: 0.2862 - accuracy: 0.8898 - val_loss: 0.4896 - val_accuracy: 0.8165\n",
            "Epoch 4/5\n",
            "107/107 [==============================] - 15s 139ms/step - loss: 0.1591 - accuracy: 0.9415 - val_loss: 0.4129 - val_accuracy: 0.8482\n",
            "Epoch 5/5\n",
            "107/107 [==============================] - 15s 137ms/step - loss: 0.1086 - accuracy: 0.9625 - val_loss: 0.5281 - val_accuracy: 0.8418\n",
            "\n",
            "\n",
            "133/133 [==============================] - 1s 6ms/step - loss: 0.5108 - accuracy: 0.8395\n",
            "\n",
            "\n",
            "Accuracy:   0.8394916653633118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8zdpWHj3hBb",
        "colab_type": "code",
        "outputId": "4a164c25-39fb-4e33-a799-c5a9a253962a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Accuracy :  ' , np.mean(score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy :   0.838982617855072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI6Mbh_D5sdX",
        "colab_type": "code",
        "outputId": "df29d917-c0ee-4ec1-f1df-535c8815d053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "pred = model_5th.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test.argmax(1),pred.argmax(1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84      2116\n",
            "           1       0.92      0.79      0.85      1535\n",
            "           2       0.86      0.83      0.84      1661\n",
            "\n",
            "    accuracy                           0.84      5312\n",
            "   macro avg       0.86      0.84      0.84      5312\n",
            "weighted avg       0.85      0.84      0.84      5312\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcVbPMwG3xRH",
        "colab_type": "text"
      },
      "source": [
        "### **Nice , the accuracy again increased. Next we will do model ensembling!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKCaI9iZ382R",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **Model ensembling(Weighted Average)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn-UvK4i4Ci5",
        "colab_type": "code",
        "outputId": "39530628-60f4-407b-e4f4-a86fbb2a07ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "pred1 = model_1.predict(X_test)\n",
        "pred2 = model_2nd.predict(X_test)\n",
        "pred3 = model_3rd.predict(X_test)\n",
        "pred4 = model_4th.predict(X_test)\n",
        "pred5 = model_5th.predict(X_test)\n",
        "\n",
        "final_pred = (pred1*0.3 + pred2*0.2 + pred3*0.2 + pred4*0.15 + pred5*0.15)\n",
        "\n",
        "print(confusion_matrix(y_test.argmax(1),final_pred.argmax(1)))\n",
        "print('\\n')\n",
        "print(classification_report(y_test.argmax(1),final_pred.argmax(1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1930   81  105]\n",
            " [ 177 1299   59]\n",
            " [ 230   53 1378]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87      2116\n",
            "           1       0.91      0.85      0.88      1535\n",
            "           2       0.89      0.83      0.86      1661\n",
            "\n",
            "    accuracy                           0.87      5312\n",
            "   macro avg       0.88      0.86      0.87      5312\n",
            "weighted avg       0.87      0.87      0.87      5312\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI5yH70qHteu",
        "colab_type": "text"
      },
      "source": [
        "### **Wow! Our weighted average model produced an accuracy of 87%, which is our highest accuracy produced by any model!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5307ESX-7IBG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# **Model Ensembling(Stacking)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkB_OZo7HuBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stacked_dataset(members, inputX):\n",
        "\tstackX = None\n",
        "\tfor model in members:\n",
        "\t\tyhat = model.predict(inputX, verbose=0)\n",
        "\t\t# stack predictions into [rows, members, probabilities]\n",
        "\t\tif stackX is None:\n",
        "\t\t\tstackX = yhat\n",
        "\t\telse:\n",
        "\t\t\tstackX = dstack((stackX, yhat))\n",
        "\t# flatten predictions to [rows, members x probabilities]\n",
        "\tstackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
        "\treturn stackX\n",
        " \n",
        "def fit_stacked_model(members, inputX, inputy):\n",
        "\t# create dataset using ensemble\n",
        "\tstackedX = stacked_dataset(members, inputX)\n",
        "\tmodel = LogisticRegression()\n",
        "\tmodel.fit(stackedX, inputy)\n",
        "\treturn model\n",
        " \n",
        "# make a prediction with the stacked model\n",
        "def stacked_prediction(members, model, inputX):\n",
        "\tstackedX = stacked_dataset(members, inputX)\n",
        "\tyhat = model.predict(stackedX)\n",
        "\treturn yhat\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcCsLJNYIEvU",
        "colab_type": "code",
        "outputId": "a2c97f55-82bd-4fda-f940-5f845f471716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "members = [model_1,model_2nd,model_3rd,model_4th,model_5th]\n",
        "for models in members:\n",
        "  _,acc = models.evaluate(X_test,y_test)\n",
        "  print('Model Accuracy: ', acc)\n",
        " \n",
        "model = fit_stacked_model(members, X_test, y_test.argmax(1))\n",
        "yhat = stacked_prediction(members, model, X_test)\n",
        "\n",
        "print(classification_report(y_test.argmax(1),yhat))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "166/166 [==============================] - 1s 8ms/step - loss: 0.3999 - accuracy: 0.8505\n",
            "Model Accuracy:  0.8505271077156067\n",
            "166/166 [==============================] - 2s 9ms/step - loss: 0.4714 - accuracy: 0.8507\n",
            "Model Accuracy:  0.8507153391838074\n",
            "166/166 [==============================] - 1s 6ms/step - loss: 0.5030 - accuracy: 0.8300\n",
            "Model Accuracy:  0.8300075531005859\n",
            "166/166 [==============================] - 1s 8ms/step - loss: 0.4809 - accuracy: 0.8174\n",
            "Model Accuracy:  0.8173945546150208\n",
            "166/166 [==============================] - 1s 7ms/step - loss: 0.5297 - accuracy: 0.8421\n",
            "Model Accuracy:  0.8420557379722595\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87      2116\n",
            "           1       0.90      0.87      0.89      1535\n",
            "           2       0.89      0.86      0.88      1661\n",
            "\n",
            "    accuracy                           0.88      5312\n",
            "   macro avg       0.88      0.88      0.88      5312\n",
            "weighted avg       0.88      0.88      0.88      5312\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4oV18R27ox2",
        "colab_type": "text"
      },
      "source": [
        "### **Nice! By stacking up the models , it produced an accuracy of 88%,which is by far the highest!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TEc7CAMDPRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}